{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of Matlab Code\n",
    "\n",
    "Does:\n",
    "- run GCC-PHAT on each pairing to get a phase angle\n",
    "- convert phase angle to geometric angle using geometry\n",
    "\n",
    "Does not:\n",
    "- Apply differential smoothing to phase angles\n",
    "- Provide an alternative algo. for GCC-PHAT (XC)\n",
    "- Use a leaky filter on geometric angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# For GCC_PHAT calc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import rfft, irfft, fftfreq, fft, ifft\n",
    "import math\n",
    "\n",
    "from itertools import combinations\n",
    "from matplotlib import animation\n",
    "\n",
    "import subprocess\n",
    "import shlex\n",
    "import glob\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- An Apache-2.0 Licensed GCC-PHAT algorithm ---\n",
    "\n",
    "\"\"\"\n",
    " Estimate time delay using GCC-PHAT \n",
    " Copyright (c) 2017 Yihui Xiong\n",
    "\n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gcc_phat(sig, refsig, fs=1, max_tau=None, interp=16):\n",
    "    '''\n",
    "    This function computes the offset between the signal sig and the reference signal refsig\n",
    "    using the Generalized Cross Correlation - Phase Transform (GCC-PHAT)method.\n",
    "    '''\n",
    "    \n",
    "    # make sure the length for the FFT is larger or equal than len(sig) + len(refsig)\n",
    "    n = sig.shape[0] + refsig.shape[0]\n",
    "\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    SIG = np.fft.rfft(sig, n=n)\n",
    "    REFSIG = np.fft.rfft(refsig, n=n)\n",
    "    R = SIG * np.conj(REFSIG)\n",
    "\n",
    "    cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n",
    "\n",
    "    max_shift = int(interp * n / 2)\n",
    "    if max_tau:\n",
    "        max_shift = np.minimum(int(interp * fs * max_tau), max_shift)\n",
    "\n",
    "    cc = np.concatenate((cc[-max_shift:], cc[:max_shift+1]))\n",
    "\n",
    "    # find max cross correlation index\n",
    "    shift = np.argmax(np.abs(cc)) - max_shift\n",
    "\n",
    "    tau = shift / float(interp * fs)\n",
    "    \n",
    "    return tau, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_anim(test_0):\n",
    "    \n",
    "    # NOTE: a \"frame\" is the smallest unit of sampled time. (aka the data is a timeseries indexed by frame count).\n",
    "    # For quick testing iteration, shrink this (aka use only the first fraction of data).\n",
    "    N_TOTAL_FRAMES = 480000\n",
    "    \n",
    "    # a \"chunk\" is a group of frames considered at a time for correlation / filtering.\n",
    "    N_FRAMES_PER_CHUNK = 480\n",
    "    \n",
    "    # Chunks needn't be discrete; they can overlap. If N_ADVANCE == N_F_PER_CHUNK then they are discrete.\n",
    "    N_ADVANCE_PER_CHUNK = 480\n",
    "    \n",
    "    # Frequency is always the same for our tests.\n",
    "    FREQUENCY_HZ = 48000\n",
    "    \n",
    "    \"\"\"Load a test from a given test folder, and compute the phase angles / true angles over time. Animate.\"\"\"\n",
    "    \n",
    "    print(f\"Running for test {test_0}...\")\n",
    "    \n",
    "    pressure_data = pd.read_csv(test_0 / \"pressures.csv\", index_col=0, header=0)\n",
    "    # display(pressure_data)\n",
    "    \n",
    "    positions = pd.read_csv(test_0 / \"positions.csv\", index_col=0, header=0)\n",
    "    # display(positions)\n",
    "\n",
    "    def n_frames_to_ms(n_frames):\n",
    "        \"\"\"Convert from some amount of frames to time in milliseconds\"\"\"\n",
    "        return n_frames/FREQUENCY_HZ*1000\n",
    "    \n",
    "    mic_pairs = list(combinations(range(positions.shape[0]), 2))\n",
    "    \n",
    "    all_pairwise_delays = []\n",
    "    all_delays_flattened = []\n",
    "    all_pairwise_angles = []\n",
    "    all_angles_per_chunk = []\n",
    "    \n",
    "    # We process frequency timeseries in smaller chunks to get one estimated DOA angle per chunk of time.\n",
    "    n_steps = 0\n",
    "    for frame_idx in range(0, N_TOTAL_FRAMES - N_FRAMES_PER_CHUNK, N_ADVANCE_PER_CHUNK):\n",
    "        n_steps += 1\n",
    "        \n",
    "        # Consider this chunk.\n",
    "        this_chunk_pressure_data = pressure_data.iloc[frame_idx:frame_idx+N_FRAMES_PER_CHUNK]\n",
    "        this_chunk_delays = []\n",
    "        this_chunk_pairwise_delays = []\n",
    "        this_chunk_pairwise_angles = []\n",
    "        this_chunk_flattened_angles = []\n",
    "        \n",
    "        # Here's where we do the heavy lifting in computing angles for each pairing!\n",
    "        for pair_idx, (mic1_idx, mic2_idx) in enumerate(mic_pairs):\n",
    "            mic1_pressure_header, mic2_pressure_header = this_chunk_pressure_data.columns[mic1_idx], this_chunk_pressure_data.columns[mic2_idx]\n",
    "\n",
    "            s1, s2 = this_chunk_pressure_data[mic1_pressure_header], this_chunk_pressure_data[mic2_pressure_header]\n",
    "            \n",
    "            # ----- COMPUTE PHASE ANGLE BETWEEN THIS PAIR -------\n",
    "            delay, _ = gcc_phat(s1, s2, FREQUENCY_HZ)\n",
    "            \n",
    "            # Prep for geometric angle calc.\n",
    "            mic1_pos = positions.iloc[mic1_idx]\n",
    "            mic2_pos = positions.iloc[mic2_idx]\n",
    "            m1x, m1y = tuple(mic1_pos)\n",
    "            m2x, m2y = tuple(mic2_pos)\n",
    "            \n",
    "            \n",
    "            # ---- PHASE ANGLE TO GEOMETRIC ANGLE CALCULATION ----\n",
    "            \n",
    "            # This was the MatLab implementation I based this off of. But I also\n",
    "            # kind of derived the setup from scratch.\n",
    "            \n",
    "            # [d,a]=distang(micpos(i,:),frequency_hz; %Calculate distance and angle between mics\n",
    "            # ra=(1:360)*pi/180-a; %Create angle vector, rotate based on mic position\n",
    "            # ds=d*cos(ra)*fs/343; %Convert to sample delay\n",
    "            # angularIndex(:,n)=round(ds)+bufferSize/2 +1; % Shift to put zero index in the middle\n",
    "\n",
    "\n",
    "            dist, pair_edge_angle = np.sqrt((m1x-m2x)**2 + (m1y-m2y)**2), math.atan2(m2x-m1x, m2y-m1y)\n",
    "            speed_times_time = 343*delay/dist\n",
    "            ang_relative_to_mic_edge = np.arccos(speed_times_time if np.abs(speed_times_time) <= 1 else 1 * np.sign(speed_times_time))\n",
    "            geometric_angles = (ang_relative_to_mic_edge - pair_edge_angle) % (2*np.pi), (ang_relative_to_mic_edge + pair_edge_angle)  % (2*np.pi)\n",
    "            \n",
    "            # ------------------------------------------------------\n",
    "            \n",
    "            this_chunk_delays.append(delay)\n",
    "            this_chunk_pairwise_delays.append(delay)\n",
    "            this_chunk_pairwise_angles.append(geometric_angles)\n",
    "            this_chunk_flattened_angles += list(geometric_angles)\n",
    "                    \n",
    "        all_pairwise_delays.append(this_chunk_pairwise_delays)\n",
    "        all_delays_flattened += this_chunk_delays\n",
    "        all_pairwise_angles.append(this_chunk_pairwise_angles)\n",
    "        all_angles_per_chunk.append(this_chunk_flattened_angles)\n",
    "     \n",
    "    # For tuning the animation\n",
    "    ANIM_LEN_SEC = 10 # 10\n",
    "\n",
    "    # For the angle est. line in the animation\n",
    "    LINE_LEN = 0.15\n",
    "     \n",
    "    ANGLE_LINE_ALPHA = 0.1\n",
    "    ANGLE_LINE_LW = 3\n",
    "    \n",
    "    EXAGGERATION = 2.\n",
    "    \n",
    "    MIC_EDGE_COLOR = (1, 0, 0)\n",
    "    MIC_EDGE_OPACITY = 0.6\n",
    "    ANGLE_LINE_COLOR = (0, 1, 0)\n",
    "\n",
    "    # Move the angle drawing right so it doesn't overlap\n",
    "    # the red lines as much (so we don't misinterpret dark overlap as a high-conf angle)\n",
    "    ANGLE_LINE_X_OFFS = 0.02\n",
    "     \n",
    "    # Create an animation \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(f\"{test_0}\")\n",
    "    ax.set(title=f\"{test_0}\", xlim=(-0.22, 0.16), ylim=(-0.16, 0.16))\n",
    "    t_text = ax.text(0.007, 0.03, \"t\")\n",
    "        \n",
    "    # Setup the orignal line color and positions of the animation.\n",
    "    # Use the last chunk done (bound to \"this_chunk_pressure_data\") to grab headers.\n",
    "    lines = []\n",
    "\n",
    "    for mic1_idx, mic2_idx in mic_pairs:\n",
    "        mic1_pos = positions.iloc[mic1_idx]\n",
    "        mic2_pos = positions.iloc[mic2_idx]\n",
    "        m1x, m1y = tuple(mic1_pos)\n",
    "        m2x, m2y = tuple(mic2_pos)\n",
    "        \n",
    "        # angle, symmetric_angle = this_chunk_pairwise_angles[pair_idx]\n",
    "\n",
    "        \n",
    "        # move edges right by factor of line length to remove overlaps\n",
    "        xo = np.sqrt((m1x - m2x)**2 + (m1y-m2y)**2) * 0.03\n",
    "        \n",
    "        # Graph the mic edge\n",
    "        mic_edge_line, = ax.plot([m1x+xo, m2x+xo], [m1y, m2y], c=MIC_EDGE_COLOR)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Graph possible angle and its symmetry\n",
    "        angle_line, = ax.plot(0, 0, c=ANGLE_LINE_COLOR, lw=ANGLE_LINE_LW, alpha=ANGLE_LINE_ALPHA)\n",
    "        angle_symmetric_line, = ax.plot(0, 0, c=ANGLE_LINE_COLOR, lw=ANGLE_LINE_LW, alpha=ANGLE_LINE_ALPHA)\n",
    "        lines.append((mic_edge_line, angle_line, angle_symmetric_line))\n",
    "  \n",
    "    max_delay, min_delay = max(all_delays_flattened), min(all_delays_flattened)\n",
    " \n",
    "    def update(chunk_idx):\n",
    "        \"\"\"For our animation. For each chunk create one animation frame, in which we update the line colors.\"\"\"\n",
    "\n",
    "        frame_idx = chunk_idx*N_ADVANCE_PER_CHUNK\n",
    "\n",
    "        this_chunk_pairwise_delays = all_pairwise_delays[chunk_idx]\n",
    "        this_chunk_pairwise_angles = all_pairwise_angles[chunk_idx]\n",
    "        \n",
    "        \n",
    "        # For each frame, we need to recolor each edge based on the delays of this chunk.\n",
    "        for pair_idx, (mic1_idx, mic2_idx) in enumerate(mic_pairs):\n",
    "            delay = this_chunk_pairwise_delays[pair_idx]\n",
    "            \n",
    "            # Since all time delays are relatively close to eachother,\n",
    "            # scale the color by first normalizing then putting through an exponential.\n",
    "            # Makes higher values *much* more intense.\n",
    "            alpha = 1 if max_delay == min_delay else np.exp(EXAGGERATION*(delay - min_delay) / (max_delay - min_delay)) / (np.exp(EXAGGERATION))\n",
    "\n",
    " \n",
    "            mic_edge_line, angle_line, angle_symmetric_line = lines[pair_idx]\n",
    " \n",
    "            mic_edge_line.set_alpha(alpha*MIC_EDGE_OPACITY)\n",
    "            mic_edge_line.set_color(MIC_EDGE_COLOR)\n",
    "            \n",
    "\n",
    "            \n",
    "            angle, symmetric_angle = this_chunk_pairwise_angles[pair_idx]\n",
    "            angle_line.set_xdata([ANGLE_LINE_X_OFFS, ANGLE_LINE_X_OFFS + LINE_LEN*np.cos(angle)])\n",
    "            angle_line.set_ydata([0, LINE_LEN*np.sin(angle)])\n",
    "            angle_symmetric_line.set_xdata([ANGLE_LINE_X_OFFS, ANGLE_LINE_X_OFFS + LINE_LEN*np.cos(symmetric_angle)])\n",
    "            angle_symmetric_line.set_ydata([0, LINE_LEN*np.sin(symmetric_angle)])\n",
    "            \n",
    "        t_text.set_text((\n",
    "            f\"Step # {chunk_idx}\\n\"\n",
    "            f\"t={n_frames_to_ms(frame_idx):.2f}ms\\n\"\n",
    "            f\"Frame # {frame_idx}\\n\"\n",
    "            f\"Chunk size:\\n  {N_FRAMES_PER_CHUNK} frames ({n_frames_to_ms(N_FRAMES_PER_CHUNK):.2f}ms)\\n\"\n",
    "            f\"frame adv. per chunk:\\n  {N_ADVANCE_PER_CHUNK} frames ({n_frames_to_ms(N_ADVANCE_PER_CHUNK):.2f}ms)\\n\"\n",
    "            \"Darker=longer delay\"\n",
    "        ))\n",
    "            \n",
    "        return *lines, t_text,\n",
    "    \n",
    "    # Save the animation.\n",
    "    ani = animation.FuncAnimation(fig, update, frames=n_steps, interval=ANIM_LEN_SEC * 1000 / n_steps)\n",
    "    test_0_same_dir= test_0.relative_to(*test_0.parts[:1])\n",
    "    ani.save(f\"{test_0_same_dir}_anim.mp4\")\n",
    "    plt.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_test_anims():\n",
    "    \"\"\"Run and animate each timeseries test, with angles computed. Outputs saved alongside this file.\"\"\"\n",
    "    test_dirs = [f for f in Path(\"Data\").iterdir() if f.is_dir()]\n",
    "\n",
    "    for test in test_dirs:  \n",
    "        run_anim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for test Data/test_01_white_noise_0_fwd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649/2377302637.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for test Data/test_02_white_noise_45_left...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649/2377302637.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for test Data/test_03_white_noise_90_left...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649/2377302637.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for test Data/test_04_engine_noise_no_talking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649/2377302637.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for test Data/test_06_engine_noise_talking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649/2377302637.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n"
     ]
    }
   ],
   "source": [
    "run_all_test_anims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_test_videos(output_video_name):\n",
    "    \"\"\"Create a unified video that combines the test videos.\n",
    "    \n",
    "    This function suppresses errors during running ffmpeg, so\n",
    "    if it's not working, make sure you have ffmpeg installed on \n",
    "    your computer.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = []\n",
    "    \n",
    "    # Grab singular test video files in this directory.\n",
    "    for f in glob.glob(\"test_*.mp4\", root_dir=\".\"):\n",
    "        files.append(f)\n",
    "    \n",
    "    # Only combine if all the test files are produced correctly.    \n",
    "    if len(files) >= 5:\n",
    "        subprocess.run(shlex.split(f\"\"\"ffmpeg -y \\\n",
    "            -i {files[0]} -i {files[1]} \\\n",
    "            -i {files[2]} -i {files[3]} \\\n",
    "            -i {files[4]} -i {files[4]} \\\n",
    "            -filter_complex \\\n",
    "            \"[0:v][1:v][2:v]hstack=inputs=3[top];\\\n",
    "            [3:v][4:v][5:v]hstack=inputs=3[bottom];\\\n",
    "            [top][bottom]vstack=inputs=2[v]\" \\\n",
    "            -map \"[v]\" \\\n",
    "            {output_video_name}\n",
    "        \"\"\"),\n",
    "            stdout = subprocess.DEVNULL,\n",
    "            stderr = subprocess.DEVNULL\n",
    "        )\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"all_tests_anim.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMBINED_NAME = \"all_tests_anim.mp4\"\n",
    "combine_test_videos(COMBINED_NAME)\n",
    "\n",
    "Video(COMBINED_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
